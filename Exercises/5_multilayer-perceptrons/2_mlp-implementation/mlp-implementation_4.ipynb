{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. How does changing the learning rate alter your results? With all other parameters fixed, which learning rate gives you the best results? How does this relate to the number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowering the learning rate makes the convergence slower, so if our learning rate was good before we just increased the number of epochs we need to get to the same result.\n",
    "\n",
    "If our current learning rate is good then and we increase it could be that our algorithm becomes unstable, jumping over potential minima and increasing the loss, or create a very unsightly loss graph which jumps up and down during the different iterations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
