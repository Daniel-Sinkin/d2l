{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Softmax gets its name from the following mapping: $\\textrm{RealSoftMax}(a, b) = \\log (\\exp(a) + \\exp(b))$.\n",
    "1. Prove that $\\textrm{RealSoftMax}(a, b) > \\mathrm{max}(a, b)$.\n",
    "1. How small can you make the difference between both functions? Hint: without loss of\n",
    "generality you can set $b = 0$ and $a \\geq b$.\n",
    "1. Prove that this holds for $\\lambda^{-1} \\textrm{RealSoftMax}(\\lambda a, \\lambda b)$, provided that $\\lambda > 0$.\n",
    "1. Show that for $\\lambda \\to \\infty$ we have $\\lambda^{-1} \\textrm{RealSoftMax}(\\lambda a, \\lambda b) \\to \\mathrm{max}(a, b)$.\n",
    "1. Construct an analogous softmin function.\n",
    "1. Extend this to more than two numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) We write $\\operatorname{RSM}(a, b) := \\operatorname{RealSoftMax}(a, b)$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{RSM}(a, b) &= \\log(\\exp(a) + \\exp(b)) \\\\\n",
    "&\\overset{1}{>} \\log(\\max(\\exp(a), \\exp(b))) \\\\\n",
    "&\\overset{2}{=} \\max(\\log(\\exp(a)), \\log(\\exp(b))) \\\\\n",
    "&\\overset{3}{=} \\max(a, b).\n",
    "\\end{aligned}\n",
    "$$\n",
    "1. $\\exp(x) > 0$ and $\\log$ is strictly monotone increasing\n",
    "2. $\\log$ is monotone increasing\n",
    "3. $\\log(\\exp(x)) = x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)\n",
    "\n",
    "By (1) we know that $|\\operatorname{RSM}(a, b) - \\max(a, b)| = \\operatorname{RSM}(a, b) - \\max(a, b)$ so the distance can be computed without an absolute value.\n",
    "\n",
    "Now let $a >= b$ then we know that\n",
    "$$\n",
    "\\lim­_{b \\rightarrow -\\infty} \\operatorname{RSM}(a, b) = \\lim­_{b \\rightarrow -\\infty} \\log(\\exp(a) + \\exp(b)) = \\log(\\exp(a)) = a = \\max(a, b)\n",
    "$$\n",
    "so the functions become arbitrarily close to each other as long for any fixed value, as long as one of the values is just small enough.\n",
    "\n",
    "Now that I look over this solution it might be that we have to assume that $a, b \\geq 0$, then the hint also makes more sense.\n",
    "\n",
    "If we have $a, b >= 0$ then of course $\\operatorname{RSM}(a, b) >= \\operatorname{RSM}(a, 0) = \\log(\\exp(a) + 1)$ and by $a \\geq b$ we have $\\max(a, b)$, so we are interested in\n",
    "$$\n",
    "\\inf­ \\underbrace{\\log(\\exp(a) + 1) - a}_{=: \\delta(a)}\n",
    "$$\n",
    "for $a \\geq a$.\n",
    "\n",
    "Now suppose $\\inf_a \\delta(a) = S > 0$ then that would imply that\n",
    "$$\n",
    "\\log(e^a + 1) - a \\geq S\n",
    "$$\n",
    "for all $a \\geq a$, putting $a$ to the RHS and exponentiating gives us the equivalent representation\n",
    "$$\n",
    "e^a + 1 \\geq e^{S + a} = e^S e^a\n",
    "$$\n",
    "which can be rewritten to \n",
    "$$\n",
    "\\frac{1}{e^S - 1} \\geq e^a\n",
    "$$\n",
    "which is a contradiction to $e^a \\rightarrow \\infty$ as $a \\rightarrow \\infty$, as such $S = 0$.\n",
    "\n",
    "Because \n",
    "$$\n",
    "\\delta'(a) = - \\frac{1}{1 + e^a} < 0\n",
    "$$\n",
    "the function $\\delta$ is strictly monotone decreasing with $\\inf \\delta(a) <= 0$, because $delta(a) >= 0$ it follows that the infimum is actually $0$ and so the funciton $\\delta$ gets arbitrarily close to $0$, i.e. $\\operatorname{RSM}(a, b)$ gets arbitrarily close to $\\max(a, b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)\n",
    "\n",
    "Assuming \"this\" refers to the statement of (1) the proof is identical because\n",
    "$$\n",
    "\\exp(\\max(\\lambda a, \\lambda b)) = \\max(\\exp(\\lambda a), \\exp(\\lambda b)).\n",
    "$$\n",
    "$$\n",
    "\\lambda^{-1} \\operatorname{RSM}(\\lambda a, \\lambda b) > \\max(a, b)\n",
    "$$\n",
    "is equivalent to\n",
    "$$\n",
    "\\operatorname{RSM}(\\lambda a, \\lambda b) > \\lambda \\max(a, b) \\overset{\\lambda > 0}{>} \\max(\\lambda a, \\lambda b).\n",
    "$$\n",
    "which holds by (1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)\n",
    "\n",
    "If $\\max(a, b) = 0$ we have $a = b = 0$ and $RSE(a, b) = \\log(2) > \\max(a, b)$. So statement actually fails in this edge case.\n",
    "\n",
    "Now suppose $a \\geq b > 0$ or $a > b \\geq 0$. Applying (3) and noting that $a \\geq b \\implies \\lambda a \\geq \\lambda b$ as well as\n",
    "$$\n",
    "\\lambda a \\rightarrow \\infty\n",
    "$$\n",
    "for $\\lambda a$ if $a > 0$ proves the statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5)\n",
    "\n",
    "Let $a, b \\geq 1$ and define\n",
    "$$\n",
    "\\operatorname{RealSoftMin}(a, b) := \\exp(\\log(a) \\cdot \\log(b)).\n",
    "$$\n",
    "\n",
    "The proof that $\\operatorname{RealSoftMin}(a, b) <= \\min(a, b)$ is similiar to the $\\operatorname{RSM}$ proof.\n",
    "\n",
    "Note that we have to multiply because $\\exp(a + b) = \\exp(a)\\exp(b)$ or equivalently $\\log(a) + \\log(b) = \\log(ab)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6)\n",
    "\n",
    "$$\n",
    "\\operatorname{RSM}(x_1, \\dots, x_n) = \\log\\left( \\sum_{i = 1}^n \\exp(x_i) \\right) > \\max(x_1, \\dots, x_n)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
