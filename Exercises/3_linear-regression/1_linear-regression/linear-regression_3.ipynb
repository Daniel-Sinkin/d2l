{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Assume that you want to find quadratic functions of $\\mathbf{x}$, i.e., $f(\\mathbf{x}) = b + \\sum_i w_i x_i + \\sum_{j \\leq i} w_{ij} x_{i} x_{j}$. How would you formulate this in a deep network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "**Key Insight:** We can apply arbitrary operations on the feature set (like multiplying them) to increase the expressiveness of our system.\n",
    "\n",
    "We define one layer that computes all products $x_ix_j$ for $1 \\leq i <= j < n$. We define a dense layer that is linear to compute the terms $b + \\sum_i w_i x_i$. We also create a dense layer with linear activation without a bias term that computes the expression $\\sum_{i \\leq j} w_{ij} x_ix_j$ based on the previously computed feature interactiosn ($x_ix_j$). Then we add the ouput of the terms.\n",
    "\n",
    "Note that if we define $\\underline{w} = (w_1, w_2, \\dots, w_n)$ and\n",
    "$$\n",
    "W = \\begin{pmatrix}\n",
    "w_{11} & 0 & \\cdots & 0 \\\\\n",
    "w_{21} & w_{22} & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{n1} & w_{n2} & \\cdots & w_{nn}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "then the function can be expressed as follows\n",
    "$$\n",
    "f(x) = b + \\underline{w} \\cdot \\underline{x} + \\underline{x}^t W \\underline{x}.\n",
    "$$\n",
    "We can flatten $W$ by embedding it into $\\mathbb{R}^{\\frac{n(n + 1)}{2}}$ (for a proof see below) and then take the dot product of the weight vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof and details of embedding\n",
    "For the dimensionality note that $W \\in \\mathbb{R}^{n \\times n}$. Removing the diagonal leaves us with $n^2 - n$ elements, half of that is $(n^2 - n) / 2$, which is exactly the number of elements we have to remove because we have a lower triangular matrix. So the number of elements we actually want to have is $n^2 - \\left( \\frac{n^2 - n}{2} \\right) = \\frac{n(n + 1)}{2}$.\n",
    "\n",
    "We want to define an explicit map $\\widetilde{\\phi} : \\R­_{\\Delta^u}^{n \\times n} \\hookrightarrow \\R^{n(n+1)/2}$, which reduces to finding an isomorphism\n",
    "$$\n",
    "\\phi : \\{(i, j) \\in \\mathbb{N} : 1 \\leq i \\leq j \\leq n\\} \\rightarrow \\{k \\in \\mathbb{N} : 1 \\leq k \\leq n(n+1)/2\\}\n",
    "$$\n",
    "\n",
    "The $kth$ row of the matrix has $k$ entries, so to get the $jth$ element of the $kth$ row ($1 \\leq j \\leq k$) is $T_k + j$ where $T_{k - 1}$ is the $kth$ triangle number, which we can compute using Gauß's little theorem (ger. kleiner Gauß)\n",
    "$$\n",
    "T_{k-1} = \\sum_{i = 1}^{k - 1} i = \\frac{(k - 1)k}{2}\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "\\phi^{-1}(T_{k - 1} + j) = (k, j).\n",
    "$$\n",
    "\n",
    "Note that the dimension of the vector space in the range is exactly $T_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch code implementation\n",
    "This is purely for future reference to recall the concepts discussed here, it's generated by Claude3 and untested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "class QuadraticFeatures(nn.Module):\n",
    "    \"\"\"\n",
    "    Module to create quadratic feature interactions from input data.\n",
    "\n",
    "    Parameters:\n",
    "    num_features (int): Number of input features.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features: int):\n",
    "        super(QuadraticFeatures, self).__init__()\n",
    "        self.num_interactions = num_features * (num_features + 1) // 2\n",
    "        self.weights = nn.Parameter(torch.randn(self.num_interactions))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the quadratic feature interactions (x_i * x_j) and applies the weights.\n",
    "        \"\"\"\n",
    "        # Could probably vectorize this computation for efficiency, something like\n",
    "        # x @ x.T probably would work, as x in R^n and x.T in R^(1 x n)\n",
    "        # so their product is in R^(n x n) and consist of all x_i * x_j\n",
    "        interactions = []\n",
    "        for i in range(x.size(1)):\n",
    "            for j in range(i, x.size(1)):\n",
    "                # Compute the pairwise product of features i and j (x_i * x_j)\n",
    "                interactions.append(x[:, i] * x[:, j])\n",
    "\n",
    "        interactions = torch.stack(interactions, dim=1)\n",
    "        return torch.matmul(interactions, self.weights)\n",
    "\n",
    "class MyQuadraticModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model that combines linear and quadratic relationships between input features and target variable.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features: int):\n",
    "        super(MyQuadraticModel, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.quadratic_features = QuadraticFeatures(num_features)\n",
    "        self.final_linear = nn.Linear(2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the model output by combining linear and quadratic outputs.\n",
    "        \"\"\"\n",
    "        linear_output = self.linear(x)\n",
    "        quadratic_output = self.quadratic_features(x)\n",
    "        combined = torch.cat((linear_output, quadratic_output.unsqueeze(1)), dim=1)\n",
    "        return self.final_linear(combined)\n",
    "\n",
    "num_features = 3\n",
    "model = MyQuadraticModel(num_features)\n",
    "input_x = torch.randn(10, num_features)\n",
    "output = model(input_x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tensor([[ 0.1154],\n",
    "        [ 0.4561],\n",
    "        [ 0.3887],\n",
    "        [ 0.4996],\n",
    "        [ 0.6570],\n",
    "        [-0.2477],\n",
    "        [ 0.5168],\n",
    "        [ 0.2347],\n",
    "        [ 0.3938],\n",
    "        [ 0.8847]], grad_fn=<MmBackward0>)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
