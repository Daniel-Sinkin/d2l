{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Recall that one of the conditions for the linear regression problem to be solvable was that the design matrix $\\mathbf{X}^\\top \\mathbf{X}$ has full rank.\n",
    "1. What happens if this is not the case?\n",
    "1. How could you fix it? What happens if you add a small amount of coordinate-wise independent Gaussian noise to all entries of $\\mathbf{X}$?\n",
    "1. What is the expected value of the design matrix $\\mathbf{X}^\\top \\mathbf{X}$ in this case?\n",
    "1. What happens with stochastic gradient descent when $\\mathbf{X}^\\top \\mathbf{X}$ does not have full rank?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)\n",
    "\n",
    "In principle it could still be solveable, just not uniquely. But the solution is also not guaranteed to exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)\n",
    "\n",
    "Because the set of invertible matrices is dense in the set of all matrices this approach would work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)\n",
    "\n",
    "Let $\\sigma^2 > 0$ be a small number, then our adjusted matrix is $X + \\varepsilon$ where $\\varepsilon \\sim \\mathcal{N}(\\mu, \\sigma^2 I)$ where $\\mu = 0$. As such\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(X + \\varepsilon)^\\top(X + \\varepsilon) &= (X^\\top + \\varepsilon^\\top)(X + \\varepsilon) \\\\\n",
    "&= X^\\top X + X^\\top \\varepsilon + \\varepsilon^\\top X + \\varepsilon^\\top \\varepsilon\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that because $\\mu = 0$ we have\n",
    "$$\n",
    "\\mathbb{E}[X^{\\top}\\varepsilon] = X^{\\top}\\mathbb{E}[\\varepsilon] = 0, \\mathbb{E}[\\varepsilon^{\\top}X] = (\\mathbb{E}[X^{\\top}\\varepsilon])^{\\top} = 0^{\\top} = 0\n",
    "$$\n",
    "as such it follows that\n",
    "$$\n",
    "\\mathbb{E}[(X + \\varepsilon)^{\\top}(X + \\varepsilon)] = X^{\\top}X + \\mathbb{E}[\\varepsilon^{\\top}\\varepsilon] \n",
    "$$\n",
    "Because\n",
    "$$\n",
    "\\mathbb{E}[\\varepsilon^{\\top}\\varepsilon] = \\sigma^2 \\operatorname{trace}(I) = \\sigma^2 n\n",
    "$$\n",
    "it follows that the expected value of our perturbed matrix is $X^tX + \\sigma^2 n I$ where $X \\in \\R^{n \\times m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)\n",
    "\n",
    "SGD won't necessary find a unique solution, but the algorithm still works."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
